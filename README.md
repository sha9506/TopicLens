# ğŸ“Š Real-Time Analytics Pipeline with Kafka, Hive, Python, Docker & Kubernetes

This project demonstrates a **real-time data processing pipeline** using Kafka for message streaming, Hive for storage and querying, and a Streamlit dashboard for visualization â€” all containerized with Docker and orchestrated using Kubernetes.

---

## ğŸš€ Overview

This pipeline simulates real-time message production (like IoT sensor data or user activity logs), processes it via a Kafka consumer, stores key analytics in Hive, and visualizes trends in a live dashboard built with Streamlit.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Producer â”‚ â”€â–¶â”€ â”‚  Kafka      â”‚ â”€â–¶â”€ â”‚  Consumer   â”‚ â”€â–¶â”€ â”‚    Hive     â”‚ â”€â–¶â”€ â”‚ Streamlit UI â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Tech Stack

| Layer              | Technology                        |
|--------------------|------------------------------------|
| Streaming Engine   | Apache Kafka                      |
| Data Storage       | Apache Hive                       |
| Data Processing    | Python (KafkaConsumer)            |
| Visualization      | Streamlit                         |
| Containerization   | Docker                            |
| Orchestration      | Kubernetes                        |

---

## ğŸ“ Folder Structure

```
real-time-analytics/
â”œâ”€â”€ producer/                  # Kafka message producer
â”œâ”€â”€ consumer/                  # Kafka consumer (Hive ingestion)
â”œâ”€â”€ dashboard/                 # Streamlit dashboard
â”œâ”€â”€ hive/                      # Hive init scripts
â”œâ”€â”€ Dockerfiles/               # Dockerfiles for each service
â”œâ”€â”€ k8s/                       # Kubernetes manifests
â”œâ”€â”€ docker-compose.yml         # For local testing
â””â”€â”€ README.md
```

---

## ğŸ“¦ Setup & Run

### ğŸ”¹ Option 1: Local (Docker Compose)

1. **Clone the repository**
   ```bash
   git clone https://github.com/<your-username>/real-time-analytics.git
   cd real-time-analytics
   ```

2. **Start containers**
   ```bash
   docker-compose up --build
   ```

3. **Access**
   - Kafdrop: [http://localhost:9000](http://localhost:9000)
   - Streamlit: [http://localhost:8501](http://localhost:8501)

---

### ğŸ”¹ Option 2: Kubernetes Deployment

1. **Apply manifests**
   ```bash
   kubectl apply -f k8s/
   ```

2. **Port-forward Streamlit**
   ```bash
   kubectl port-forward service/streamlit-service 8501:8501
   ```

3. **Port-forward Hive (if needed)**
   ```bash
   kubectl port-forward service/hive-service 10000:10000
   ```

---

## ğŸ“Š Sample Use Case

The pipeline can simulate data like:
```json
{"user_id": 1, "action": "login", "timestamp": "2025-06-17T10:00:00"}
```

It is ingested by Kafka, consumed, stored in Hive, and displayed as:
- Most active users
- Action trends over time
- Live message count

---

## ğŸ§  Skills Demonstrated

- Real-time stream processing with Kafka
- Building Kafka producers and consumers with Python
- Working with Hive for analytical queries
- Dockerizing and deploying microservices
- Deploying a complete stack on Kubernetes
- Building dashboards with Streamlit

---

## ğŸ“¸ Screenshots

> Add screenshots of:
> - Streamlit dashboard
> - Kafdrop UI
> - Hive query results

---

## ğŸ§ª To Do / Extensions

- Integrate Spark Streaming or Flink
- Add authentication to Streamlit
- Integrate Kafka Connect for external DBs
- Set up Grafana + Prometheus monitoring

---

## ğŸ¤ Contributing

Contributions welcome! Please open issues or PRs for improvements.

---

## ğŸ“ License

MIT License